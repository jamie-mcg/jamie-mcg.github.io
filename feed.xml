<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jamie-mcg.github,io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jamie-mcg.github,io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-01T21:14:59+00:00</updated><id>https://jamie-mcg.github,io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Convexity Explained</title><link href="https://jamie-mcg.github,io/blog/2024/convexity/" rel="alternate" type="text/html" title="Convexity Explained"/><published>2024-01-29T15:12:00+00:00</published><updated>2024-01-29T15:12:00+00:00</updated><id>https://jamie-mcg.github,io/blog/2024/convexity</id><content type="html" xml:base="https://jamie-mcg.github,io/blog/2024/convexity/"><![CDATA[<h2 id="introduction">Introduction</h2> <h2 id="what-is-convexity">What is convexity?</h2> <p>Quote: A function is convex if the line segment between two points lies above the function.</p> <p>FIGURE</p> <p>In the above figure, we see an illustrative example of the definition above. Here, we can see that if the intersection of the line forms an enclosed area which is uninterrupted above the curve, the function can be considered convex.</p> <p>We can also see that if the opposite is true i.e. the enclosed area is below the curve, the function is concave!</p> <p>Indeed, a convex function \(f(x)\) can be reflected into a concave function \(-f(x)\).</p> <p>Mathematically, convexity is best described by Jensen’s inequality,</p> <p>EQUATION</p> <p>JENSEN CHAT</p> <p>Additionally, for a twice differentiable function which is convex, we have two rather nice conditions:</p> \[f^{''}(x) &gt;= 0 \forall x, f(y) &gt;= f(x) + \nabla f(x)^{T} (y-x).\] <p>The first of these conditions tells us that curvature must be positive everywhere. The second condition ensures that the line between two points $x$ and $y$ lies above the function within that interval (illustrated earlier).</p> <p>Following on from this, the first condition ensures that a convex function must curve upwards (or not at all). Therefore, if we find a minima x, any movement away from this point will result in an increase in the function value.</p> <p>Together, these conditions are enough to guarantee that any minima found in a convex function must be a global minima (although this doesn’t necessarily need to be unique). This is extremely useful for techniques such as stochastic Gradient Descent since if we find a local minima (something which Gradient Descent generally tends to find), we can be certain that this in fact the global minima - the best possible solution.</p> <h2 id="the-strong-the-strict-and-the-standard">The Strong, the Strict and the Standard</h2> <p>As always with math, we don’t just have one type of something, we have some vague terms that sound cool to describe some more features.</p> <p>Convex functions are no exception and can be further categorised with three properties:</p> <ul> <li>Convex</li> <li>Strictly Convex</li> <li>Strongly Convex</li> </ul> <p>Now, the further you move down that list, the stronger these properties become (hence the “strongly” term). This just means that the subset of convex functions that have these properties becomes smaller due to stronger constraints.</p> <p>So far in this post, we have been talking about convexity in its most general form, where \(f^{''}(x) &gt;= 0\). This is the condition for ‘convex’ functions.</p> <p>Strictly convex functions are those which satisfy \(f^{''}(x) &gt; 0\), i.e. the curvature can never be 0.</p> <p>Stongly convex functions are those which satisfy \(f^{''}(x) &gt;= m &gt; 0\), where the curvature is non-vanishing and stays bounded below by some positive value $m$.</p>]]></content><author><name></name></author><category term="mathematics"/><category term="math"/><category term="optimisation"/><summary type="html"><![CDATA[A short and easy to follow primer on convexity.]]></summary></entry><entry><title type="html">What the Lipschitz?!</title><link href="https://jamie-mcg.github,io/blog/2024/lipschitz/" rel="alternate" type="text/html" title="What the Lipschitz?!"/><published>2024-01-29T15:12:00+00:00</published><updated>2024-01-29T15:12:00+00:00</updated><id>https://jamie-mcg.github,io/blog/2024/lipschitz</id><content type="html" xml:base="https://jamie-mcg.github,io/blog/2024/lipschitz/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Lipschitzness of a function is essential for ensuring the convergence properties of many gradient descent algorithms</p> <h2 id="definition">Definition</h2> <p>Simply put, Lipschitz functions are those which do not explode for some value $x$. So, functions which change too fast and/or become infinitely steep are not Lipschitz functions.</p> <p>More formally, let $\chi \in R^{d}$ be a d-dimensional subspace of real values. If we take a function $f: R^{d} \rightarrow R^{n}$ which provides a mapping from a d-dimensional space to a p-dimensional space, we can say that $f$ is $L$-Lipschitz over $\chi$ if and only if we have:</p> \[|f(x_{2}) - f(x_{1})| \le L | x_{1} - x_{2} | \forall x_{1}, x_{2} \in \chi\] <p>I always think this looks a bit confusing written this way, so a more intuitive way to write it is simply:</p> \[\frac{|f(x_{2}) - f(x_{1})|}{ | x_{1} - x_{2} | } \le L \forall x_{1}, x_{2} \in \chi\] <p>where we now have the form of $\Delta y / \Delta x$ on the left hand side.</p> <p>Thinking about this a bit more, this condition demands that the slope of the secant line between two points $x_{1}$ and $x_{2}$ must be between $-L \le m \le L$.</p> <h3 id="example-is-cosine-lipschitz">Example: Is cosine Lipschitz?</h3> <p>Start by employing the definition above,</p> \[\frac{f(x) - f(y)}{x - y} \simeq f^{'}(x) = \text{sin}(x)\] <table> <tbody> <tr> <td>We know that $</td> <td>\text{sin}(x)</td> <td>\le 1$, so we can rewrite this as:</td> </tr> </tbody> </table> \[|f(x) - f(y)| \le L | x - y |\] <p>where L = 1. So we say that cosine is a 1-Lipschitz function.</p> <h2 id="globally--locally-lipschitz">Globally &amp; Locally Lipschitz</h2> <p>Just to round off this small post, I want to talk a bit about global and local Lipschitz functions. The above section kind of describes functions which are globally Lipschitz since we haven’t defined a subset of the function space to consider, so here, we’ll start local!</p> <p>Say for example, we have some function $f$ which is locally Lipschitz for a compact subset of $\chi$. We’ll call this $\Omega \subset \chi \in R^{d}$.</p> <p>For the local Lipschitz property to hold, it must be true that there is a constant $L_{\Omega}$ such that,</p> \[|f(x) - f(y)| \le L_{\Omega} | x - y |, \forall x_{1}, x_{2} \in \Omega\] <p>where $L_{\Omega}$ can indeed depend on the subset $\Omega$. For example, the function $f(x) = x^{2}$ has an $L_{\Omega}$ which depends on $x$ (since only one of the $x^{2}$ will cancel). Therefore as the subset $\Omega$ becomes larger, $L_{\Omega}$ will scale linearly with this.</p> <p>The above example defines a situation where we have local Lipschitzness but not global!</p> <p>For global Lipschitzness, we require the function to have a Lipschitz constant which does not depend on the subset $\Omega$, i.e. $L_{\Omega} = L$.</p> <p>I hope this post has been a useful primer into the property of Lipschitzness. As always, feel free to reach out with any comments/questions!</p>]]></content><author><name></name></author><category term="mathematics"/><category term="math"/><category term="optimisation"/><summary type="html"><![CDATA[A short and easy to follow primer on convexity.]]></summary></entry><entry><title type="html">A Detailed Introduction to Training Dynamics of Neural Networks</title><link href="https://jamie-mcg.github,io/blog/2024/training-dynamics-1/" rel="alternate" type="text/html" title="A Detailed Introduction to Training Dynamics of Neural Networks"/><published>2024-01-29T15:12:00+00:00</published><updated>2024-01-29T15:12:00+00:00</updated><id>https://jamie-mcg.github,io/blog/2024/training-dynamics-1</id><content type="html" xml:base="https://jamie-mcg.github,io/blog/2024/training-dynamics-1/"><![CDATA[<h2 id="introduction">Introduction</h2> <h2 id="setting-up-our-playground">Setting up our playground</h2> <p>Althogh simple, linear regression is a powerful setting for us to gain intuition around more complex neural network phenomena. Indeed, with this extremely simple playground, many questions surrounding the dynamics of optimization can be answered analytically.</p> <p>Let’s begin with a simple linear regression model that has a mapping $R^{N}\rightarrow R$ (i.e. the output is a scalar value):</p> \[y = \mathbf{w}^{T}\mathbf{\psi}(\mathbf{x}) + b\] <p>where $\mathbf{\psi}(\mathbf{x}) \in R^{N}$ is the feature representation of the input vector $\mathbf{x} \in R^{N}$ and $\mathbf{w} \in R^{N}$ is a weight vector that, together with the bias $b \in R$, defines the parameters of our toy model.</p> <p>Next, every great model needs a problem to solve. So let’s take our loss function to be a regression loss of:</p> \[\mathcal{L} = \frac{1}{2}||\mathbf{w}^{T}\mathbf{\psi}(\mathbf{x}) + b - \hat{y}||^{2}\] <p>where $\hat{y} \in R$ is the true value we are attempting to predict for some input $\mathbf{x}$.</p> <p>Given some data pairs $\mathcal{D} \sim {\mathbf{x}<em>{i}, y</em>{i}}^{N}_{i=1}$, we now wish to minimise the function $\mathcal{L}$ above with</p> <p>\(w^{*} \in argmin_{w} \mathcal{L}(\mathbf{w})\) \(= argmin_{w} \frac{1}{2N} \sum_{i=1}^{N} (\mathbf{w}^{T}\mathbf{\psi(\mathbf{x}_{i})} + b - \hat{y}_i)^{2}\) \(= argmin_{w} \frac{1}{2N} ||\mathbf{W}^{T}\mathbf{\Psi(\mathbf{x}_{i})} - \hat{Y}||^{2}\)</p> <p>where in the above, we have absorbed the bias into the weight vector $\mathbf{W} = (\mathbf{w}, b)$ and defined $\mathbf{\Psi} = (\mathbf{\psi}, 1)$.</p> <p>Note that in the 1st line of the argmin equation above, we also use the symbol $\in$ as the minimum is by no means guaranteed to be unique - in fact it is much more likely in general to be part of a set. In these cases, the optimum that we find during training will depend entirely upon the dynamics.</p> <p>Let’s take a quick look at what we have so far though. In particular, the function we really want to understand is the loss function!</p> <p>Note that in the above we can see this loss function is indeed a convex quadratic, meaning that our dynamics should be very well behaved (i.e. positive curvature everywhere and a unique global minimum).</p> <p>Aside: Everyone always throws the term convex about in the literature as a way to explain away a lot of training dynamics. When you’re starting out, it is easy to overlook what this term really means! Take a look at my other post on convexity to give yourself a brief primer on this subject!</p>]]></content><author><name></name></author><category term="mathematics"/><category term="math"/><category term="optimisation"/><summary type="html"><![CDATA[A short and easy to follow primer on convexity.]]></summary></entry></feed>